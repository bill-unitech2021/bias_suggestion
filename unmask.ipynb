{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# 加载模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def complete_text(masked_text):\n",
    "    # 对文本进行编码\n",
    "    input = tokenizer.encode(masked_text, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "\n",
    "    # 预测掩码位置的词\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "    predicted_token_id = output[0, 0, mask_token_index, :].argmax(axis=1)\n",
    "    predicted_token = tokenizer.decode(predicted_token_id[0])\n",
    "\n",
    "    # 生成补全后的文本\n",
    "    return masked_text.replace(tokenizer.mask_token, predicted_token)\n",
    "\n",
    "# 示例\n",
    "masked_sentence = \"Hello I'm a [MASK] model.\"\n",
    "complete_text(masked_sentence)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

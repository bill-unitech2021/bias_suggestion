{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libnvToolsExt.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/bias_suggestion/unmask.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m BertTokenizer, BertForMaskedLM\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m# 加载模型和分词器\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     logging,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     50\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdependency_versions_table\u001b[39;00m \u001b[39mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[39m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[39m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtqdm\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpyyaml\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/utils/__init__.py:31\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdoc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     25\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     ContextManagers,\n\u001b[1;32m     33\u001b[0m     ExplicitEnum,\n\u001b[1;32m     34\u001b[0m     ModelOutput,\n\u001b[1;32m     35\u001b[0m     PaddingStrategy,\n\u001b[1;32m     36\u001b[0m     TensorType,\n\u001b[1;32m     37\u001b[0m     add_model_info_to_auto_map,\n\u001b[1;32m     38\u001b[0m     cached_property,\n\u001b[1;32m     39\u001b[0m     can_return_loss,\n\u001b[1;32m     40\u001b[0m     expand_dims,\n\u001b[1;32m     41\u001b[0m     find_labels,\n\u001b[1;32m     42\u001b[0m     flatten_dict,\n\u001b[1;32m     43\u001b[0m     infer_framework,\n\u001b[1;32m     44\u001b[0m     is_jax_tensor,\n\u001b[1;32m     45\u001b[0m     is_numpy_array,\n\u001b[1;32m     46\u001b[0m     is_tensor,\n\u001b[1;32m     47\u001b[0m     is_tf_symbolic_tensor,\n\u001b[1;32m     48\u001b[0m     is_tf_tensor,\n\u001b[1;32m     49\u001b[0m     is_torch_device,\n\u001b[1;32m     50\u001b[0m     is_torch_dtype,\n\u001b[1;32m     51\u001b[0m     is_torch_tensor,\n\u001b[1;32m     52\u001b[0m     reshape,\n\u001b[1;32m     53\u001b[0m     squeeze,\n\u001b[1;32m     54\u001b[0m     strtobool,\n\u001b[1;32m     55\u001b[0m     tensor_size,\n\u001b[1;32m     56\u001b[0m     to_numpy,\n\u001b[1;32m     57\u001b[0m     to_py_obj,\n\u001b[1;32m     58\u001b[0m     transpose,\n\u001b[1;32m     59\u001b[0m     working_or_temp_dir,\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     62\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     63\u001b[0m     DISABLE_TELEMETRY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     try_to_load_from_cache,\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     93\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     94\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    195\u001b[0m     torch_required,\n\u001b[1;32m    196\u001b[0m )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/utils/generic.py:432\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 432\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pytree\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_torch_pytree\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[Any], \u001b[39m\"\u001b[39m\u001b[39m_torch_pytree.Context\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    435\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(output\u001b[39m.\u001b[39mvalues()), (\u001b[39mtype\u001b[39m(output), \u001b[39mlist\u001b[39m(output\u001b[39m.\u001b[39mkeys()))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/utils/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_osp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mthroughput_benchmark\u001b[39;00m \u001b[39mimport\u001b[39;00m ThroughputBenchmark\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcpp_backtrace\u001b[39;00m \u001b[39mimport\u001b[39;00m get_cpp_backtrace\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_registration\u001b[39;00m \u001b[39mimport\u001b[39;00m rename_privateuse1_backend, generate_methods_for_privateuse1_backend\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/utils/throughput_benchmark.py:2\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_time\u001b[39m(time_us\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, time_ms\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, time_s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      6\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Defines how to format time'''\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: libnvToolsExt.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, BertForMaskedLM\n",
    "import torch\n",
    "\n",
    "# 加载模型和分词器\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def complete_text(masked_text):\n",
    "    # 对文本进行编码\n",
    "    input = tokenizer.encode(masked_text, return_tensors=\"pt\")\n",
    "    mask_token_index = torch.where(input == tokenizer.mask_token_id)[1]\n",
    "\n",
    "    # 预测掩码位置的词\n",
    "    with torch.no_grad():\n",
    "        output = model(input)\n",
    "    predicted_token_id = output[0, 0, mask_token_index, :].argmax(axis=1)\n",
    "    predicted_token = tokenizer.decode(predicted_token_id[0])\n",
    "\n",
    "    # 生成补全后的文本\n",
    "    return masked_text.replace(tokenizer.mask_token, predicted_token)\n",
    "\n",
    "# 示例\n",
    "masked_sentence = \"Hello I'm a [MASK] model.\"\n",
    "complete_text(masked_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'rand'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/bias_suggestion/unmask.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrand(\u001b[39m5\u001b[39m, \u001b[39m3\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(x)\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'torch' has no attribute 'rand'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(5, 3)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "libnvToolsExt.so.1: cannot open shared object file: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m/workspaces/bias_suggestion/unmask.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtransformers\u001b[39;00m \u001b[39mimport\u001b[39;00m pipeline\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m unmasker \u001b[39m=\u001b[39m pipeline(\u001b[39m'\u001b[39m\u001b[39mfill-mask\u001b[39m\u001b[39m'\u001b[39m, model\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mbert-base-uncased\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://codespaces%2Bubiquitous-enigma-pqq574vv9gg3qvp/workspaces/bias_suggestion/unmask.ipynb#W2sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m unmasker(\u001b[39m\"\u001b[39m\u001b[39mHello I\u001b[39m\u001b[39m'\u001b[39m\u001b[39mm a [MASK] model.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/__init__.py:26\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtyping\u001b[39;00m \u001b[39mimport\u001b[39;00m TYPE_CHECKING\n\u001b[1;32m     25\u001b[0m \u001b[39m# Check the dependencies satisfy the minimal versions required.\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m dependency_versions_check\n\u001b[1;32m     27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     OptionalDependencyNotAvailable,\n\u001b[1;32m     29\u001b[0m     _LazyModule,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     46\u001b[0m     logging,\n\u001b[1;32m     47\u001b[0m )\n\u001b[1;32m     50\u001b[0m logger \u001b[39m=\u001b[39m logging\u001b[39m.\u001b[39mget_logger(\u001b[39m__name__\u001b[39m)  \u001b[39m# pylint: disable=invalid-name\u001b[39;00m\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/dependency_versions_check.py:16\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# Copyright 2020 The HuggingFace Team. All rights reserved.\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m# Licensed under the Apache License, Version 2.0 (the \"License\");\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m# See the License for the specific language governing permissions and\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39m# limitations under the License.\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdependency_versions_table\u001b[39;00m \u001b[39mimport\u001b[39;00m deps\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mversions\u001b[39;00m \u001b[39mimport\u001b[39;00m require_version, require_version_core\n\u001b[1;32m     19\u001b[0m \u001b[39m# define which module versions we always want to check at run time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[39m# (usually the ones defined in `install_requires` in setup.py)\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39m# order specific notes:\u001b[39;00m\n\u001b[1;32m     23\u001b[0m \u001b[39m# - tqdm must be checked before tokenizers\u001b[39;00m\n\u001b[1;32m     25\u001b[0m pkgs_to_check_at_runtime \u001b[39m=\u001b[39m [\n\u001b[1;32m     26\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpython\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     27\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtqdm\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mpyyaml\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m     38\u001b[0m ]\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/utils/__init__.py:31\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mconstants\u001b[39;00m \u001b[39mimport\u001b[39;00m IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD, IMAGENET_STANDARD_MEAN, IMAGENET_STANDARD_STD\n\u001b[1;32m     23\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdoc\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     24\u001b[0m     add_code_sample_docstrings,\n\u001b[1;32m     25\u001b[0m     add_end_docstrings,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     replace_return_docstrings,\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 31\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mgeneric\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     32\u001b[0m     ContextManagers,\n\u001b[1;32m     33\u001b[0m     ExplicitEnum,\n\u001b[1;32m     34\u001b[0m     ModelOutput,\n\u001b[1;32m     35\u001b[0m     PaddingStrategy,\n\u001b[1;32m     36\u001b[0m     TensorType,\n\u001b[1;32m     37\u001b[0m     add_model_info_to_auto_map,\n\u001b[1;32m     38\u001b[0m     cached_property,\n\u001b[1;32m     39\u001b[0m     can_return_loss,\n\u001b[1;32m     40\u001b[0m     expand_dims,\n\u001b[1;32m     41\u001b[0m     find_labels,\n\u001b[1;32m     42\u001b[0m     flatten_dict,\n\u001b[1;32m     43\u001b[0m     infer_framework,\n\u001b[1;32m     44\u001b[0m     is_jax_tensor,\n\u001b[1;32m     45\u001b[0m     is_numpy_array,\n\u001b[1;32m     46\u001b[0m     is_tensor,\n\u001b[1;32m     47\u001b[0m     is_tf_symbolic_tensor,\n\u001b[1;32m     48\u001b[0m     is_tf_tensor,\n\u001b[1;32m     49\u001b[0m     is_torch_device,\n\u001b[1;32m     50\u001b[0m     is_torch_dtype,\n\u001b[1;32m     51\u001b[0m     is_torch_tensor,\n\u001b[1;32m     52\u001b[0m     reshape,\n\u001b[1;32m     53\u001b[0m     squeeze,\n\u001b[1;32m     54\u001b[0m     strtobool,\n\u001b[1;32m     55\u001b[0m     tensor_size,\n\u001b[1;32m     56\u001b[0m     to_numpy,\n\u001b[1;32m     57\u001b[0m     to_py_obj,\n\u001b[1;32m     58\u001b[0m     transpose,\n\u001b[1;32m     59\u001b[0m     working_or_temp_dir,\n\u001b[1;32m     60\u001b[0m )\n\u001b[1;32m     61\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mhub\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     62\u001b[0m     CLOUDFRONT_DISTRIB_PREFIX,\n\u001b[1;32m     63\u001b[0m     DISABLE_TELEMETRY,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     90\u001b[0m     try_to_load_from_cache,\n\u001b[1;32m     91\u001b[0m )\n\u001b[1;32m     92\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mimport_utils\u001b[39;00m \u001b[39mimport\u001b[39;00m (\n\u001b[1;32m     93\u001b[0m     ENV_VARS_TRUE_AND_AUTO_VALUES,\n\u001b[1;32m     94\u001b[0m     ENV_VARS_TRUE_VALUES,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    195\u001b[0m     torch_required,\n\u001b[1;32m    196\u001b[0m )\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/transformers/utils/generic.py:432\u001b[0m\n\u001b[1;32m    428\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mtuple\u001b[39m(\u001b[39mself\u001b[39m[k] \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkeys())\n\u001b[1;32m    431\u001b[0m \u001b[39mif\u001b[39;00m is_torch_available():\n\u001b[0;32m--> 432\u001b[0m     \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_pytree\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_torch_pytree\u001b[39;00m\n\u001b[1;32m    434\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m_model_output_flatten\u001b[39m(output: ModelOutput) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[List[Any], \u001b[39m\"\u001b[39m\u001b[39m_torch_pytree.Context\u001b[39m\u001b[39m\"\u001b[39m]:\n\u001b[1;32m    435\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(output\u001b[39m.\u001b[39mvalues()), (\u001b[39mtype\u001b[39m(output), \u001b[39mlist\u001b[39m(output\u001b[39m.\u001b[39mkeys()))\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/utils/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mos\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpath\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39m_osp\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mthroughput_benchmark\u001b[39;00m \u001b[39mimport\u001b[39;00m ThroughputBenchmark\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mcpp_backtrace\u001b[39;00m \u001b[39mimport\u001b[39;00m get_cpp_backtrace\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbackend_registration\u001b[39;00m \u001b[39mimport\u001b[39;00m rename_privateuse1_backend, generate_methods_for_privateuse1_backend\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/site-packages/torch/utils/throughput_benchmark.py:2\u001b[0m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_C\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mformat_time\u001b[39m(time_us\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, time_ms\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, time_s\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m      6\u001b[0m \u001b[39m    \u001b[39m\u001b[39m'''Defines how to format time'''\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: libnvToolsExt.so.1: cannot open shared object file: No such file or directory"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
    "unmasker(\"Hello I'm a [MASK] model.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
